\subsection{Results}

\input{strmsum/tables/rouge_cumulative.tex}
\input{strmsum/figures/rougetime.tex}

\paragraph{\textsc{Rouge}} \autoref{tab:rouge} shows our results for system output samples against the 
full summary of nuggets using \textsc{Rouge}. SAP improves over the individual
component systems, i.e. affinity propagation only (AP) or salience prediction
only (RS), suggesting the combination of these two components is beneficial. 
This improvement is statistically 
significant for all ngram precision, recall, and F-measures at the 
$\alpha = .01$ level using the Wilcoxon signed-rank test. 
The full system or the individual components AP and RS also outperform 
the alternative clustering method HAC. 

%Differences between AP and RS
%are relatively small, suggesting they have complentary strengths 



SAP maintains its performance above the baselines over time 
as well. \autoref{fig:trouge} shows the \textsc{Rouge-1} scores over time. We show 
the difference in unigram precision (bigram precision is not shown but it 
follows similar curve). Within the initial days of the event, 
SAP is able to take the lead over the other systems in ngram 
precision. The SAP model is better able to find salient 
updates earlier on; for news and crisis informatics, 
this is an especially important 
quality of the model. 
Moreover, the SAP's recall is not diminished by the high 
precision and remains competitive with \textsc{AP}. Over time 
SAP's recall also begins to pull away, while the other models
begin to plateau.

\input{strmsum/figures/gaincompauto.tex}

\paragraph{Expected Gain and Comprehensiveness}
\autoref{fig:nperf} shows the expected gain across a range of similarity 
thresholds, where thresholds closer to 1 are more conservative estimates. 
The ranking of the systems remains constant across the sweep with 
\textsc{SAP} beating all baseline systems. Predicting salience in 
general is helpful for keeping a summary on topic as the \textsc{RS} approach 
outperforms the clustering only approaches on expected gain.


When looking at the comprehensiveness of the summaries \textsc{AP} outperforms
\textsc{SAP}. The compromise encoded in the \textsc{SAP} 
objective function, between being representative and being salient, is seen 
clearly here where the performance of the \textsc{SAP} methods is 
lower bounded by the salience focused \textsc{RS} system and upper bounded by 
the clustering only \textsc{AP} system. Overall, \textsc{SAP} achieves
the best balance of these two metrics.


\subsection{Feature Ablation}
\input{strmsum/figures/rouge_fa.tex}


\autoref{tab:farouge} shows the results of our feature ablation tests. 
Removing the language models yields a statistically significant drop in both 
ngram recall and F-measure. 

Removing the language model and geographic relevance features leads to a
statistically significant drop in \textsc{Rouge-1} F1 scores. Unfortunately,
this is not the case for the temporal relevance features. We surmise that
these features are too strongly correlated with each other, 
i.e. the differences in TF-IDF between hours are definitely not i.i.d. 
variables. 

Interestingly, removing the basic features leads 
to an increase in both unigram and bigram precision; in the bigram case this 
is enough to cause a statistically significant increase in F-measure over the 
full model. In other words, the generic features actually lead to an inferior 
model when we can incorporate more appropriate domain specific features.
This result perhaps echoes the claim of \cite{ksj98} that generic approaches to 
summarization are unlikely to produce truly useful summaries.





