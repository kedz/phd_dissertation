\subsection{Introduction}

While our previous summarization model proved reasonably capable of
summarizing events over time, by processing the stream in hourly batches it
was limited in its ability to respond quickly to unfolding events. One reason
for this limitation is an implicit assumption in that model, and most
multi-document summarization models, that frequency of a unit of text is a
proxy for its salience. In retrospective summarization of static document
collections, this is a reasonable assumption, and has been exploited
successfully in various ways: TF-IDF term weightings, document language models
derived from frequency, and random-walks on sentence-graphs  whose edges are
determined by frequently co-occurrring terms
\citep{lin2000,radev2004,erkan2004,mihalcea2004,daume2005b,nenkova2005}. 

In the streaming setting these proxy features are constantly evolving. There
may be fallow periods in an event where nothing happens and then sudden
bursts of activity. The behavior of SAP is unsuited for this, in that it 
is run every hour regardless. 
In the SAP model, by collecting an hour's worth of documents and performing a 
salience-biased
clustering, we try to walk the line between using clustering, where the
frequency of like text units are effectively votes for the most salient unit,
and predictions about salience from our regression model, which makes more use
of the semantics of the query event and text unit under analysis.
However, as we showed in the feature ablation, incorporating time-based
frequency features made the model worse. While we are able to incorporate
salience estimate successfully into the summarization model with SAP, we 
have yet to successfully provide a learning-based of model the entire 
summarization process.

In this section, we attempt to overcome these limitations, removing the
clustering component from the update selection, and develop a fully online
streaming summarization model, one that learns to make extraction decisions
immediately upon seeing the next sentence from $\sentstream$, using features
derived from the entire observed document stream, the state of the current
update summary, and the model's prior extraction decisions.  To that end, we
present a novel streaming-document summarization system based on sequential
decision making.  Specifically, we adopt the ``learning to search'' approach,
a technique which adapts methods from reinforcement learning for structured
prediction problems \citep{daume2009,ross2010}.  In this
framework, we cast streaming summarization as a form of greedy search and
train our system to imitate the behavior of an oracle summarization system.
Effectively, we train a linear classifier to predict when to extract a
sentence $\strmSent \in \sentstream$ using features of the sentence, query,
previous summary updates, and other aggregate statistics collected from the
stream up to the current time $\systemtime_t$. 

As in the previous section,  we report both the TREC 2015 Temporal
Summarization shared-task manual evaluation as well as our own independent
automatic evaluation.  In our evaluation we demonstrate a 28.3\% improvement
in summary $\mathcal{H}_L(\updateSummary)$ and a 43.8\% improvement in
time-sensitive $\mathcal{H}_L(\updateSummary)$ metrics against several
state-of-the-art baselines.  In shared-task evaluation of our system at TREC
2015, where we were the second-best performing team in the main evaluation,
and top system for a secondary evaluation run on a pre-filtered, highly
relevant  document stream.



 
%  Given a stream of sentence-segmented news webpages and an event query  (e.g.
% ``Boston marathon bombing''), our system monitors the stream to detect
% relevant, comprehensive, novel, and timely content.  In response, our
% summarizer produces a series of short text updates describing  the event as
% it unfolds over time.  We present an example of our realtime update stream in
% Figure~\ref{fig:system-summary}.  We evaluate our system in a crisis
% informatics setting on a diverse set of event queries, covering severe
% storms, social unrest, terrorism, and large accidents. We demonstrate a
% 28.3\% improvement in summary $F_1$ and a 43.8\% improvement in
% time-sensitive $F_1$ metrics against several state-of-the-art baselines. 
% 
