\section{Results} \label{sec:results}

Results for system runs are shown in \autoref{fig:tr15autoresults}.  On
average, \textsc{L2S} and \textsc{L2S-Cos} achieve higher
$\mathcal{H}(\updateSummary)$ scores than the baseline systems in both latency
penalized and unpenalized evaluations. For \textsc{L2S-Cos}, the difference in
mean $\mathcal{H}(\updateSummary)$ score was significant compared to all other
systems (for both latency settings). Intuitively, L2S has higher comprehensiveness than \textsc{L2S-Cos}; adding the the cosine similairt filter to L2S 
reduces the comprehensiveness, but increases the average gain of the 
updates by a larger amount, yielding an improved harmonic mean of the two
metrics ($\mathcal{H}(\updateSummary)$).
 
\textsc{SAP} achieved the overall highest expected gain, partially because it
was the tersest system we evaluated (at 8 updates per query on average).
However, only \textsc{Cos} was statistically significantly worse than it on
this measure. We also see that SAP suffers from the latency-weighted evaluation, receiving latency penalties for retrieving updates after that information
had been added to Wikipedia. By comparison, all other systems are actually 
rewarded in the latency-weighted evaluation, as they consistently
retrieve information before it is published in Wikipedia. While SAP
had previously beaten Wikiepdia in previous evaluations, the added events
for the 2015 Temporal Summarization had less media coverage, suggesting
the clustering based approach is less suited for lower-volume news streams.

\input{strmsum/tables/lolsautoeval.tex}
 
In comprehensiveness, \textsc{L2S} recalls on average a fifth of the nuggets
for each event. This is even more impressive when  compared to the average
number of updates produced by each system; while \textsc{Cos} achieves similar
comprehensiveness, it takes on average about 1.6 times more updates than
\textsc{L2S} and almost 5 times more updates than \textsc{L2S-Cos}. The output
size of \textsc{Cos} stretches the limit of the term ``summary,'' which is
typically far shorter than 145 sentences in length.  This is especially
important if the intended application is negatively affected by verbosity
(e.g. crisis monitoring).

\input{strmsum/tables/fseval.tex}



\section{Discussion} \label{sec:discussion}

  Since \textsc{Cos} only considers the first sentence of each document, it
 may miss relevant sentences below the article's lead. In order to confirm the
 importance of modeling the oracle, we also trained and evaluated the
 \textsc{L2S} based approaches on first sentence only streams. 
 \autoref{tab:results-trunc} shows the latency penalized results of the first
 sentence only runs.  The \textsc{L2S} approaches still dominate \textsc{Cos}
 and receive larger positive effects from the latency penalty despite also
 being restricted to the first sentence. Clearly having a model (beyond
 similarity) of what to select is helpful. Ultimately we do much better when
 we can look at the whole document.
  

 \input{strmsum/tables/errors.tex}
 
 We also performed an error analysis to further understand how each system
 operates.  \autoref{tab:errors} shows the errors made by each system on
 the test streams.  Errors were broken down into four categories. \emph{Miss
 lead} and \emph{miss body} errors occur when a system skips a sentence
 containing a novel nugget in the lead or article body respectively. An
 \emph{empty} error indicates an update was selected that contained no nugget.
 \emph{Duplicate} errors occur when an update contains nuggets but none are
 novel. 
 
  Overall, errors of the miss type are most common and suggest future
 development effort should focus on summary content identification.  About a
 fifth to a third of all system error comes from missing content in the lead
 sentence alone.
 
  After misses, empty errors (false positives) are the next largest source of
 error. \textsc{Cos} was especially prone to empty errors (41\% of its total
 errors). \textsc{L2S} is also vulnerable to empties (19.9\%) but after
 applying the similarity filter and restriting to first sentences, these
 errors can be reduced dramatically (to 1\%).
  
  Surprisingly, duplicate errors are a minor issue in our evaluation. This is
 not to suggest we should ignore this component, however, as efforts to
 increase recall (reduce miss errors) are likely to require more robust
 redundancy detection. 


