
\input{nlg/figures/beamsearch.tex}

\subsection{Inference}

As stated above, $\gen\left(\cdot|\ls\left(\mr\right)\right)$ is a conditional language model.
Given some \meaningrepresentation~$\mr$, a natural utterance one might want to infer is the 
maximum a posteriori (MAP)
 utterance \[\predutttoks = \argmax_{\utttoks\in\uttSize} \log\gen\left(\utttoks|\ls\left(\mr\right)\right) \] under the model.\footnote{Technically, we are only considering valid finite utterances, i.e. $\utttoks = \left[\utttok_1,\ldots,\utttok_\uttSize\right]$ with $\utttok_1 = \starttok$ and $\utttok_\uttSize = \stoptok$. } Unfortunately, the search implied by the $\argmax$
is intractable. Instead an approximate search is performed. The most commonly used search
is called \textit{beam search} \citep{reddy1977} or beam decoding. 
Under beam search, a set $\mathcal{H}$ 
of $\nbest$-best
candidate utterances is maintained throughtout the search. $\nbest$ is referred
to as the beam size or beam width. At each step $i$ of the search,
the next word continuations are computed for each candidate utterance prefix, yielding $\nbest \times \lvert\uttvocab\rvert$ utterances,
from which the top-$\nbest$ under some search criterion are selected, and $\mathcal{H}$ is updated the with
the $\nbest$ utterances of length $i+1$. 
When a completed utterance enters $\mathcal{H}$ (i.e. $\utttok_{i+1} = \stoptok$), it is added to a set of
completed utterances, $\mathcal{H}_{complete}$, and removed from $\mathcal{H}$.
After exploring the maximum number of steps $T$ (or some other heurstic
stopping criterion), $\mathcal{H}_{complete}$ is reranked according some heuristic 
reranking criteria, and the top-ranked  utterance is returned.
When the beam size
is 1, we refer to algorithm as greedy search or greedy decoding.
See \autoref{alg:beamsearch} for a formal description of the algorithm.

Common reranking criteria include the length-normalized log likelihood,
\[ \operatorname{rerank-score}(\utttoks,\mr) = \frac{\sum_{i=1}^\setsize{\utttoks} \log \gen(\utttok_i|\utttoks_{1:i-1},\ls(\mr))}{\setsize{\utttoks}}\]
or a mixture of model likelihood and an auxilliary  language model, $\gen_{LM}$,
\[ \operatorname{rerank-score}(\utttoks,\mr) = \log\gen(\utttoks|\ls(\mr)) + \lambda \log \gen_{LM}(\utttoks).\]
The latter method is popular in machine translation where it is easier
to obtain a large monolingual corpus with which to train a language model
than it is to obtain a large parallel corpus for training the translation model \cite{xie2017neural}. When using \sequencetosequence~models for the 
\meaningrepresentation-to-text generation problem, practitioners often incorporate
a discriminative \meaningrepresentation~parser, $\dmodel(\cdot|\cdot) : \mrspace \times \outSpace \rightarrow (0,1)$,
in the reranker,
\[ \operatorname{rerank-score}(\utttoks,\mr) = \log\dmodel(\mr|\utttoks),\]
which can help to select the most semantically correct utterances from the beam
candidates.
 

Despite its wide adoption and empirical success, however, 
there are many known issues with beam search.
The output may repeat phrases or words \citep{soemthig}, or may never even terminate \citep{welleck2020consistency}.
While these issues are often linked to differences in the maximum likelihood learning objective
and test-time search procedure \citep{lafferty2001,andor2016}, the problems are possibly deeper as 
increasing the beam size often leads to worse empirical performance \citep{koehn2017}. In fact, the biases present in beam search are actually beneficial when compared to exact search \citep{stahlberg2019}.
Additionally, it is well known that the set of output
beam candidates may lack diversity and only differ by a small number of words \citep{sordoni2015,galley2015,li2016,vinyals2015,serban2016},


