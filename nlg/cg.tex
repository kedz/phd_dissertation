%
%Let $\mr \in \mrspace$ be a \meaningrepresentation~with a \dialogueact~$\mrtok_0$
%and $\mrSize$ \attributevalues~$\mrtok_1,\ldots,\mrtok_\mrSize$, and let
%$\utttoks = \left[\utttok_1,\ldots,\utttok_\uttSize\right]$ be 
%an utterance that denotes $\mr$, which we write as $\denotes{\utttoks} = \mr$.
%A contiguous span of utterance tokens $\utttoks_{i:j} = \left[\utttok_i,\ldots,\utttok_j\right]$, for $i \le j$, 
%can denote zero or more \attributevalues, that is,
%$\denotes{\utttoks_{i:j}} = \{\mrtok_{k_1}, \mrtok_{k_2}, \ldots\}$. We further define a ``denotation
%set'' of $\mr$ and $\utttoks$ as $\denotationset = \left\{(i^{(k)},j^{(k)}): k \in \left\{1,\ldots,\mrSize\right\} \right\}$ where 
%$\denotes{\utttoks_{i^{(k)}:j^{(k)}}} = \{ \mrtok_k \}$. In other words,
%$\denotationset$ is the set of utterance token spans that denote a single
%\attributevalue.
%
%\autoref{fig:explans} shows an example of controllable \surfacerealization~for the \meaningrepresentation
% \begingroup
% \renewcommand*\arraystretch{.6}
%\begin{align} \mr =  \left[\!\!\left[ \begin{array}{l} (\mrtok_0)\; \textsc{Inform} \\ (\mrtok_1)\; \textrm{name=Aromi} \\ (\mrtok_2)\; \textrm{area=city centre} \\ (\mrtok_3)\; \textrm{eat\_type=coffee shop} \end{array} \right]\!\!\right]\label{eqn:mr1}\end{align}
%\endgroup
%when following either one of two different linearizations \[\ls^{(1)}(\mr) = \left[ \mrtok_0, \mrtok_1, \mrtok_3, \mrtok_2 \right]\quad \textrm{and} \quad \ls^{(2)}(\mr) = \left[ \mrtok_0, \mrtok_3, \mrtok_2, \mrtok_1 \right].\] When using a controllable model, 
%we refer to a linearization $\ls$ as an \utteranceplan. In this work, 
%a \linearizationstrategy~will only permute the location of \attributevalue~tokens, while the \dialogueact~token $\mrtok_0$ will always occupy the first
%position of any \meaningrepresentation~token sequence $\mrtoks$. 
%
%
%
%\begin{figure}
%\begin{subfigure}{\textwidth}
%\caption{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}
%\center
%\fbox{\begin{minipage}{0.87\textwidth}
%\begin{tabular}{cccccc}
%\multirow{2}{*}{$\ls^{(1)}(\mr) = \Bigg[$} & $x_0$ &   $x_{\pi_1}$ & $x_{\pi_2}$ & $x_{\pi_3}$ & \multirow{2}{*}{$\Bigg]$}\\
%& inform & name=Aromi & eat\_type=coffee shop & area=city center \\
%\end{tabular}
%
%~\\[5pt]
%
%\begin{tabular}{cccccccccccc}
%\multirow{2}{*}{~~~~~~$\utttoks^{(1)} = \Bigg[$} & $y_1$ & $y_2$ & $y_3$ & $y_4$ & $y_5$ & $y_6$ & $y_7$ & $y_8$ & $y_9$ & $y_{10}$ & \multirow{2}{*}{$\Bigg]$} \\
%&Aromi & is & a & coffee & shop & in & the & city & centre & . \\
%\end{tabular}
%
%~\\[5pt]
%
%\begin{tabular}{ccccc}
% \multirow{2}{*}{~~$\denotationset_{\mr,\utttoks^{(1)}} = \Bigg\{$} & $(i^{(\pi_1)},j^{(\pi_1)})$ & 
%    $(i^{(\pi_2)},j^{(\pi_2)})$ & 
%    $(i^{(\pi_3)},j^{(\pi_3)})$ & \multirow{2}{*}{$\Bigg\}$}  \\
%   &  (1, 1) & (2, 5) & (6, 9) 
%\end{tabular}
%
%
%\begin{center}
%\begin{tabular}{ccc}
%$\utttoks^{(1)}_{i^{(\pi_1)}:j^{(\pi_1)}}$ & 
%$\utttoks^{(1)}_{i^{(\pi_2)}:j^{(\pi_2)}}$ &
%$\utttoks^{(1)}_{i^{(\pi_3)}:j^{(\pi_3)}}$   \\
%\cmidrule(lr){1-1}
%\cmidrule(lr){2-2}
%\cmidrule(lr){3-3}
%    $\left[\textrm{Aromi}\right]$ & $\left[\textrm{is a coffee shop}\right]$ &
%        $\left[\textrm{in the city center}\right]$ \\ 
%\end{tabular}
%\end{center}
%\end{minipage}}
%\end{subfigure}
%
%%Aromi\textsubscript{1} is\textsubscript{2} a\textsubscript{3} coffee\textsubscript{4} shop\textsubscript{5} in\textsubscript{6} the\textsubscript{7} city\textsubscript{8} centre\textsubscript{9} .\textsubscript{10}
%
%~\\
%~\\
%
%\begin{subfigure}{\textwidth}
%\caption{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}
%\begin{tabular}{cccccc}
%\multirow{2}{*}{$\ls^{(2)}(\mr) = \Bigg[$} & $x_0$ &   $x_{\pi_1}$ & $x_{\pi_2}$ & $x_{\pi_3}$ & \multirow{2}{*}{$\Bigg]$}\\
%& inform & eat\_type=coffee shop & area=city center & name=Aromi\\
%\end{tabular}
%
%~\\[5pt]
%
%\begin{tabular}{cccccccccccccc}
%\multirow{2}{*}{~~~~~~$\utttoks^{(2)} = \Bigg[$} & $y_1$ & $y_2$ & $y_3$ & $y_4$ & $y_5$ & $y_6$ & $y_7$ & $y_8$ & $y_9$ & $y_{10}$ & $y_{11}$& $y_{12}$ & \multirow{2}{*}{$\Bigg]$} \\
%&For & coffee & in & the & centre & of & the & city & , & try & Aromi & .\\
%\end{tabular}
%
%~\\[5pt]
%
%\begin{tabular}{ccccc}
% \multirow{2}{*}{~~$\denotationset_{\mr,\utttoks^{(2)}} = \Bigg\{$} & $(i^{(\pi_1)},j^{(\pi_1)})$ & 
%    $(i^{(\pi_2)},j^{(\pi_2)})$ & 
%    $(i^{(\pi_3)},j^{(\pi_3)})$ & \multirow{2}{*}{$\Bigg\}$}  \\
%   &  (1, 2) & (3, 8) & (11, 11) 
%\end{tabular}
%
%~\\[5pt]
%
%\begin{tabular}{ccc}
%$\utttoks^{(2)}_{i^{(\pi_1)}:j^{(\pi_1)}}$ & 
%$\utttoks^{(2)}_{i^{(\pi_2)}:j^{(\pi_2)}}$ &
%$\utttoks^{(2)}_{i^{(\pi_3)}:j^{(\pi_3)}}$   \\
%    $\left[\textrm{For coffee}\right]$ & $\left[\textrm{in the centre of the city}\right]$ &
%        $\left[\textrm{Aromi}\right]$ \\ 
%\end{tabular}
%\end{subfigure}
%
%~\\
%
%\caption{Examples of two possible utterance plans for $\mr$ (defined \autoref{eqn:mr1}) implied by
%the linearizations $\ls^{(1)}$ (a) and $\ls^{(2)}$ (b), their realizations $\utttoks$, denotation sets $\denotationset_{\mr,\utttoks}$, and corresponding
%attribute-value spans $\utttoks_{i:j}$.}
%\label{fig:explans}
%\end{figure}











%Assume we have a
%training corpus $\corpus = \left\{\left(\mr^{(1)}, \utttoks^{(1)}\right), \ldots, \left( \mr^{(\corpusSize)}, \utttoks^{(\corpusSize)}\right) \right\}$
%
%%That is, given such a model $\model$,
%% a \dialogueact~$\mrtok_0$ a series of \attributevalues~$\mrtok_1,\mrtok_2,\ldots,\mrtok_\mrSize$, the conditional distribution,
%%\[\model\left(\cdot|\mrtok_0,\mrtok_1,\ldots,\mrtok_\mrSize;\params\right)\]
%%prefers utterances $\utttoks$ such that \attributevalues~are realized 
%%in the order specified 
%
%In the \alignmenttraining~linearization,
%during training the order of
%attribute-value pairs $\attr_1, \attr_2, \ldots, \attr_\size{\mr}$
%matches the order in which they are realized in the
%corresponding training utterance.
%This is feasible because in the majority of cases, there is a one-to-one
%mapping of attribute-values and utterance sub-spans.
%
%
%We obtain this ordering using a manually constructed set of matching rules
%to identify which utterance sub-spans correspond to each attribute-value
%pair (see \autoref{sec:align}).




\newcommand{\lsname}[1]{\textsc{#1}}
\newcommand{\lsshort}[1]{\textsc{#1}}
\newcommand{\size}[1]{|#1|}
\newcommand{\lin}{\pi}
\newcommand{\valstr}[1]{\textit{#1}}
\newcommand{\uttstr}[1]{\textit{#1}}
\newcommand{\alignshort}{AT}
\newcommand{\enc}{Enc}
\newcommand{\rep}{h}
\newcommand{\attrval}[2]{#1=#2}
\newcommand{\phraseAug}{+p}
\newcommand{\DA}[1]{\textsc{#1}}


%At test time, when there is no reference utterance \lsshort{At}
%cannot specify a linearization. However, models trained with \lsshort{At}
%can generate an  utterance from an arbitrary utterance plan
%$\attr_1, \attr_2, \ldots, \attr_{\size{\mr}}$
%provided by an external source, such as an utterance planner model or human
%reference.








  

\subsection{Results}


\paragraph{\lsshort{At} models accurately follow utterance plans.} See
\autoref{tab:main.e2e.test} and \autoref{tab:main.viggo.test} for results on
E2E Challenge and ViGGO test sets respectively.  
The best non-\Oracle~results are bolded for each model and results
that are not different with statistical significance to the best results
are underlined.
We see that the \lsshort{At+NUP}
strategy consistently receives the lowest semantic error rate and highest 
order accuracy, regardless of
architecture or dataset, suggesting that alleviating the model's decoder of content
planning is highly beneficial to avoiding errors. The Transformer \lsshort{At} model is able to consistently achieve virtually zero semantic error on the E2E Challenge dataset using either
the bigram or neural planner model.

We also see that fine-tuned BART is able to learn to follow an utterance plan
as well. When following the neural utterance planner,
BART is highly competitive with the trained from scratch Transformer
on the E2E Challenge dataset and surpassing it on the ViGGO dataset in terms of semantic error rate.

\input{nlg/tables/main_e2e_test.tex}
%\input{nlg/tables/main_viggo_test.tex}




%{\color{red}
    Generally, the \lsshort{At} models had a smaller variance in test-set
evaluation measures over the five random initializations as compared to the
other strategies. This is reflected in some unusual equivalency classes
by statistical significance. For example, on the E2E Challenge dataset biGRU models,
the \lsshort{At+NUP+p} strategy acheives 0\% semantic error and is significantly
different than all other linearization strategies \textbf{except} 
the \lsshort{Fp} strategy even though the absolute difference in score is 
6.54\%. This is unusual because the \lsshort{At+NUP+p} strategy \textbf{is} 
significantly different from \lsshort{At+NUP} but the absolute difference is
only 0.26\%. This happens because the variance in test-set results
is higher for \lsshort{Fp} making it harder to show signficance with only
five samples.


%the difference in semantic error rate between the \lsshort{At} 
%model with and without phrase augmenation \textbf{is} significant at 0.2\% SER
%absolute. The \lsshort{If} model with phrase augmentation
%is \textbf{not} significantly different 

%\lsshort{At (NUP)+p} is significantly better than \lsshort{At (BgUP)}
%(0\% vs 0.2\%), but \textbf{not} \lsshort{If +p} (0\% vs 0.3\%).}





%and is highly competitive with the trained from scratch Transformer
%on the E2E dataet (Transformer \textsc{At} (NUP), 0\% SER vs. BART
%\textsc{At} (NUP) 0.2\% SER), and surpasses the trained from scratch model in
%the small data ViGGO setting (Transformer \textsc{At} (NUP), 2.7\% SER vs.
%BART \textsc{At} (NUP) 0.54\% SER). 

\paragraph{Transformer-based models are more faithful than biGRU on
\textsc{Rnd, Fp}, and \textsc{If} linearizations.} On the ViGGO dataset, BART
and Transformer \lsshort{If} achieve 1.86\% and 7.50\% semantic error rate 
respectively, while
the biGRU \lsshort{If} model has 19.20\% semantic error rate. These trends hold for \lsshort{Fp}
and \lsshort{Rnd}, and on the E2E dataset as well. Because there is no
sequential correspondence in the input, it is possible that the recurrence in
the biGRU makes it difficult to ignore spurious input ordering effects.
Additionally, we see that \lsshort{Rnd} does offer some benefits of denoising;
\lsshort{Rnd} models have lower semantic error rate than \lsshort{If} models in 3 of 6 cases 
and \lsshort{Fp} models in 5 out of 6 cases.

\paragraph{Model based plans are easier to follow than human reference plans.
} On E2E, there is very little difference in semantic error rate when following either the
bigram-based utterance planner, \BgUP, or neural utterance planner,
\NUP. This is also true of the ViGGO \BART~models as well.  In the
small data (i.e. ViGGO) setting, \biGRU~and \Transformer~models achieve better semantic error rate when following the neural utterance planner.  In most cases,
neural utterance planner models have slightly higher \bleu~and \rougel~than
the bigram utterance planner, suggesting the neural planner produces utterance plans closer to
the reference orderings. The neural and bigram planner models have slightly lower semantic error rate
than when following the \Oracle~utterance plans.  This suggests that the model-based planners
are producing orders more commonly seen in the training data, similar to how
neural language generators frequently learn the least interesting, lowest
entropy responses \citep{serban2016}.  On the other hand, when given
the \Oracle~orderings, models achieve much higher word overlap with the
reference, e.g. achieving an E2E \textsc{Rouge-L} $\ge 77$.

\input{nlg/tables/main_perm.tex}

\paragraph{Phrase-training reduces SER.} We see that phrase data improves semantic error rate
in 8 out of 12 cases, with the largest gains coming from the biGRU
\lsshort{If} model.  Where the base semantic error rate was higher, phrase training has a more
noticeable effect. After phrase training, all E2E models are operating at near
zero semantic error rate and almost perfectly following the neural utterance planner. Model performance on ViGGO
is more varied, with phrase training slighting hurting the biGRU
\lsshort{At+NUP} model, but otherwise helping performance.
%while improving for BART
%\lsshort{At (NUP)} models, but improving the Transformer.

\paragraph{Random Permutation Stress Test} Results of the random permutation
experiment are shown in \autoref{tab:perm}.  Overall, all models have an
easier time following the neural utterance planner's reordering of
the random
permutations. Phrase training also generally improved semantic error rate.  All models perform
quite well on the E2E permutations.  
%Models had an easier time following the
%neural utterance planner's reordering compared to the random permutations, but
With phrase-training,
all E2E models achieve less than 0.6\% semantic error rate following random 
utterance plans.
Starker differences emerge on the ViGGO dataset.  The biGRU\textsc{+NUP+p} model
achieves a 8.98\% semantic error rate and only correctly follows the given 
order 64.5\% of
the time, which is a large decrease in performance compared to the ViGGO test set.% (1.62\% SER and 94.3\% OA).

\input{nlg/tables/main_human.tex}

\paragraph{Human Evaluation} Results of the human evaluation are shown in
\autoref{tab:human}. We show the number of times each system was ranked 1
(most natural), 2, or 3 (least natural) and the average rank overall.
Overall, we see that BART  with the neural utterance planner 
and phrase-augmentation training is
preferred on both datasets, suggesting that the utterance planner is
producing natural orderings of the attribute-values, and the model can
generate reasonable output for it. On the E2E dataset, we also see small
differences in between the \lsshort{At+p} and \lsshort{At} models
suggesting that when following an arbitrary ordering, the phrase-augmented
model is about as natural as the non-phrase trained model. This is encouraging
as the phrase trained model has lower semantic error rates. 
On the ViGGO dataset we do find
that the phrase trained model is less natural, suggesting that in the small
data setting, phrase-training may hurt fluency when trying to follow a
difficult utterance plan.

For agreement we compute average Kendall's $\tau$ between each pair of
annotators for each dataset. On E2E, we have $\tau=.853$ and ViGGO we have
$\tau=.932$ suggesting very strong agreement.
%($\tau=0$ would indicate rankings
%are random, and $\tau=-1$ would indicate annotators preferred completely
%opposite models). 

\subsection{Discussion}

One consistently worrying sign throughout the first two experiments is that the
automatic metrics are not good indicators of semantic correctness.  For
example the \rougel~score of the E2E \lsshort{At Oracle} models is about 8
points higher than the \lsshort{At+NUP} models, but the \lsshort{At+NUP}
models make fewer semantic errors. Other similar examples can be found where
the automatic metric would suggest picking the more error prone model over
another. As generating fluent text becomes less of a difficult a problem,
these shallow ngram overlap methods will cease to suffice as distinguishing
criteria.

The second experiments also reveal limitations in the controllable model's
ability to follow arbitrary orderings. The biGRU and Transformer models in the
small-data ViGGO setting are not able to generalize effectively on
non-training distribution utterance plans. BART performance is much
better here, but is still hovering around 2\% semantic error rate and only roughly 88\% of
outputs conform to the intended utterance plan.  Thankfully, if an exact
ordering is not required, using the neural utterance planner to propose an order leads to more
semantically correct outputs.


\subsection{Limitations}

While we are able to acheive very low test-set SER for both corpora, we 
should caution that this required extensive manual development of matching 
rules to produce MR/utterance alignments, which in turn resulted in 
significant cleaning of the training datasets. We chose to do this over 
pursuing a model based strategy of aligning utterance subspans to 
attribute-values %predicting the semantic correctness
because we wanted to better understand how systematically S2S models can
represent arbitray order permutations independent of alignment model error. 
%so that
%an upper bound on this representational capacity might be estimated. 

%There are, of course, many other works that either separately or jointly
%model the semantic correctness \cite{nie2019,kedzie2019}, and additionally the semantic segmentation \cite{wiseman2018,shen2020,li2020} which
% could be used in practice to avoid such manual efforts.

Also we should note that 
%while possibly less glamorous than proposing novel
%model architecture, 
data cleaning can yield more substantial decreases in
semantic errors \citep{dusek2019,hongminwang2019} and is an important 
consideration in any practical neural NLG.
