\subsection{Relating Between \MeaningRepresentations~and \Utterances}

Let $\mr \in \mrspace$ be a \meaningrepresentation, and let $\utttoks = \left[\utttok_1,\ldots,
\utttok_\uttSize \right] \in \outSpace$ be an utterance, i.e. sequence of $\uttSize$ tokens from a vocabulary 
$\uttvocab$ and $\outSpace = \uttvocab^*$. We say that an utterance $\utttoks$ \textit{denotes} a \meaningrepresentation~$\mr$,
which we write $\denotes{\utttoks} = \mr$ if the propositional content of the utterance and the
meaning representation are the same, i.e. the \attributevalues~implied by $\utttoks$ and explicitly 
listed by $\mr$ are the same. 
We can make similar statements about a sub-sequence of an utterance. Let 
$\utttoks_{i:i+j} = \left[\utttok_i, \utttok_{i+1},\ldots, \utttok_{i+j} \right]$ 
be a
sub-sequence of $j+1$ tokens starting at token $i$. 
We then have $\denotes{\utttoks_{i:i+j}} = \mr^\prime$ for some $\mr^\prime \in \mrspace$.  


As an example, consider the following \meaningrepresentation,
\begin{singlespace}
\[
    \mr = \left[\!\!\left[ \begin{array}{l}
        \textsc{Inform} \\
        \AV{name}{The Vaults}\\
        \AV{eat\_type}{pub}\\
        \AV{near}{Caf{\'e} Adriatic}\\
        \AV{family\_friendly}{no}\\
\end{array}\right]\!\!\right] 
\]
\end{singlespace}
and the utterance,
\[\utttoks = \left[ \textit{The},\,\textit{Vaults},\,\textit{pub},\,\textit{is},\,\textit{near},\,\textit{Caf{\'e}},\,\textit{Adriatic},\,\textit{.},\,\textit{It},\,\textit{is},\,\textit{not},\,\textit{a},\,\textit{good},\,\textit{place},\,\textit{for},\,\textit{families},\,\textit{.}\right]. \]
\noindent Clearly, $\denotes{\utttoks} = \mr$. But we can also look at the meanings of individual
phrases,\begin{singlespace}
    \begin{align*}
        \denotes{\utttoks_{1:2}} = \left[\!\!\left[ \left[\textit{The}, \textit{Vaults}  \right] \right]\!\!\right] & = \left[\!\!\left[
\begin{array}{l} \textrm{---} \\ \AV{name}{The Vaults}\end{array} \right]\!\!\right] \\
    \denotes{\utttoks_{3:3}} = \left[\!\!\left[ \left[\textit{pub}  \right] \right]\!\!\right] &= \left[\!\!\left[
\begin{array}{l} \textrm{---} \\ \AV{eat\_type}{pub}\end{array} \right]\!\!\right] \\
    \denotes{\utttoks_{5:7}} = \left[\!\!\left[ \left[\textit{near}, \textit{Caf{\'e}}, \textit{Adriatic}  \right] \right]\!\!\right] & = \left[\!\!\left[
\begin{array}{l} \textrm{---} \\ \AV{near}{Caf{\'e} Adriatic}\end{array} \right]\!\!\right] \\
    \denotes{\utttoks_{11:16}} = \left[\!\!\left[ \left[\textit{not}, \textit{a}, \textit{good}, \textit{place}, \textit{for}, \textit{families}  \right] \right]\!\!\right] & = \left[\!\!\left[
\begin{array}{l} \textrm{---} \\ \AV{family\_friendly}{no}\end{array} \right]\!\!\right]. 
\end{align*}
\end{singlespace}
Note that it is not the case that $\denotes{\utttoks} = \mr \Rightarrow \denotes{\utttoks_{i:i+j}} \subseteq \mr$. Consider in the example above $\utttoks_{11:16}$ its sub-sequence $\utttoks_{12:16} = \left[\textit{a},\,\textit{good},\,\textit{place},\,\textit{for},\,\textit{families}\right]$ which have
the following denotations,
\begin{singlespace}
   \[
   \denotes{\utttoks_{11:16}} = \left[\!\!\left[\begin{array}{l}\textrm{---}\\ \AV{family\_friendly}{yes} \end{array}\right]\!\!\right] \ne \denotes{\utttoks_{12:16}}= \left[\!\!\left[\begin{array}{l}\textrm{---}\\ \AV{family\_friendly}{no} \end{array}\right]\!\!\right] 
       \]
   \end{singlespace}
\noindent It is also important to note that the \attributevalues~are
unordered and do not necessarily reflect the realization order of the 
utterance. 


   In the datasets used for this chapter, $\mr$ are provided with one or more reference uttterances, $\utttoks^{(1)}, \ldots \utttoks^{(k)}$ and that for each reference $\utttoks^{(i)}$, we have that each 
\attributevalue~in $\mr$ can be mapped to an 
utterance sub-sequence that denotes it.
Occasionally this is not the case in the available
training data. For example, some \attributevalues~may have several possible
groundings (see \hyperref[fig:nlgerrors]{\autoref{fig:nlgerrors}a})
%no possible grounding (see \hyperref[fig:nlgerrors]{\autoref{fig:nlgerrors}b}),
or be realized using inferential knowledge not explicitly 
represented in the \meaningrepresentation~(see \hyperref[fig:nlgerrors]{\autoref{fig:nlgerrors}b}). 

\input{nlg/figures/badann.tex}

While such examples may exist in the training data, 
we consider model 
generation of such phenomena to constitute a failure to faithfully generate
an utterance.  
 In the overwhelming majority of cases, each \attributevalue~is explicitly and uniquely grounded in the 
target utterances, this makes \surfacerealization~from 
\meaningrepresentations~a useful task to study faithful generation. The
baseline task of correctly generating all \attributevalues~appropriately 
for the \dialogueact~is hard enough, and it in this setting we do not have
to worry about ungrounded information or information that is not explicitly
represented in the \meaningrepresentations~but is deducable from
the \meaningrepresentation~\citep{wiseman2017}.  
 



%
%pairs are provided for training a
%\naturallanguagegeneration~model such that each \attributevalue~can be mapped to an 
%utterance sub-sequence that denotes it.
%of words 
%(or subwords) in the 
%reference utterance.
%
%
%
%
%
%
%
%
%
%
%%\begin{figure}
%%\center
%%%\begin{tabular}{cp{9cm}}
%%\begin{subfigure}{.35\textwidth}
%%\center
%%$\left[\begin{array}{l} 
%%    \textsc{Inform} \\ 
%%    \textrm{name=The Vaults} \\
%%    \textrm{eat\_type=pub} \\
%%    \textrm{customer\_rating=5 out of 5} \\
%%    \textrm{near=Caf{\'e} Adriatic} \\
%%    \textrm{price\_range=more than \pounds 30}
%%\end{array}\right]$ 
%%\caption{\emph{Inform} dialog act.}
%%\end{subfigure}\hfill \begin{subfigure}{.58\textwidth}
%%\begin{itemize}
%%    \item The Vaults pub near Caf{\'e} Adriatic has a 5 star rating. Prices start at \pounds 30.
%%    \item Located near Caf{\'e} Adriatic, the Vaults is a 5 star rated pub. Prices range above \pounds 30.
%%\end{itemize}
%%\caption{Natural language utterances.}
%%\label{fig:mr1utt}
%%\end{subfigure}
%%\caption{An example \meaningrepresentation~(a) and example utterances (b)
%%from the restaurant domain.}
%%\label{fig:mr1}
%%\end{figure}
%
%
%\autoref{fig:mr1utt} shows some possible realizations of the 
%\meaningrepresentation. It is important to note that the \attributevalues~are
%unordered and do not necessarily reflect the realization order of the 
%utterance. In the datasets used for this chapter,  \meaningrepresentations~are
% paired with at least one reference utterance, and for the most part
%each \attributevalue~uniquelt maps to a span of words (or subwords) in the 
%reference utterance. See \autoref{fig:mr2align} where the mapping is made
%explicit for the first utterance realization from \autoref{fig:mr1utt}.
%
%
%%\begin{figure}
%%\center
%%%\begin{tabular}{cp{9cm}}
%%\begin{subfigure}{.35\textwidth}
%%\center
%%$\left[\begin{array}{l} 
%%    \textsc{Inform} \\ 
%%    \textrm{(1) name=The Vaults} \\
%%    \textrm{(2) eat\_type=pub} \\
%%    \textrm{(3) customer\_rating=5 out of 5} \\
%%    \textrm{(4) near=Caf{\'e} Adriatic} \\
%%    \textrm{(5) price\_range=more than \pounds 30}
%%\end{array}\right]$ 
%%\caption{\emph{Inform} dialog act.}
%%\end{subfigure}\hfill \begin{subfigure}{.58\textwidth}
%%  [The Vaults]\textsubscript{(1)} [pub]\textsubscript{(2)} [near Caf{\'e} Adriatic]\textsubscript{(4)} [has a 5 star rating.]\textsubscript{(3)} [Prices start at \pounds 30.]\textsubscript{(5)}
%%\caption{Natural language utterances.}
%%
%%\end{subfigure}
%%\caption{An example \meaningrepresentation~(a) and example utterances (b)
%%from the restaurant domain.}
%%\label{fig:mr2align}
%%\end{figure}
%
%
%
%
%
%
%\begin{figure}
% \begin{subfigure}{\textwidth}
%    \begin{minipage}{0.5\textwidth}
%\center
%$\left[\begin{array}{l} 
%    \textsc{Inform} \\ 
%    \textrm{name=Portal 2} \\
%    \textrm{esrb=E 10+ (for Everyone 10 and Older)} \\
%    \textrm{genres=[platformer, puzzle, shooter]} \\
%    \textrm{player\_perspective=[first person]} \\
%    \textrm{has\_multiplayer=yes}
%\end{array}\right]$ 
%\end{minipage}
%    \begin{minipage}{0.5\textwidth}
%        Portal 2 was rated E 10+ (for Everyone 10 and
%        Older). It is a puzzle platformer FPS with
%        multiplayer.
%\end{minipage}
%
%~\\
%
%\caption{An example of list-valued attributes (genres and player\_perspective)
%    from the video game domain. Note that the acronym FPS means ``first person
%shooter'' which realizes both a genre \attributevalue~and the 
%player\_perspective \attributevalue.}
%\end{subfigure}  
%
%~\\
%~\\
%~\\
%
%\begin{subfigure}{\textwidth}
%    \begin{minipage}{0.5\textwidth}
%    \center
%$\left[\begin{array}{l} 
%    \textsc{Request} \\ 
%    \textrm{specifier=``dull''} \\
%    \textrm{has\_multiplayer=yes}
%\end{array}\right]$ 
%\end{minipage}\begin{minipage}{0.5\textwidth}
%    What's the most dull multiplayer game you've ever played?
%\end{minipage}
%
%~\\
%
%\caption{An example of a free-text valued attribute (specifier) from the 
%video game domain. The specifier value can be any adjective.}
%\end{subfigure}  
%
%~\\
%~\\
%~\\
%
%\begin{subfigure}{\textwidth}
%    \begin{minipage}{0.5\textwidth}
% \center
%$\left[\begin{array}{l} 
%    \textsc{Inform Count} \\ 
%    \textrm{count=$58$} \\
%    \textrm{type=laptop} \\
%    \textrm{is\_for\_business\_computing=true} \\
%    \textrm{weight\_range=don't care} \\
%    \textrm{drive\_range=don't care} \\
%\end{array}\right]$ 
%\end{minipage}
%\begin{minipage}{0.5\textwidth}
%There are 58 laptops used for business computing if you do not care what 
%weight range or drive range they have.
%\end{minipage}
%
%~\\
%
%
%\caption{An example of a numeric-valued attribute (count) from the laptop domain.}
%\end{subfigure}  
%
%   
%%inform_count(count=58;type=laptop;isforbusinesscomputing=true;weightrange=dontcare;driverange=dontcare
%\caption{Examples of various \attributevalue~types paired with an example
%realization.}
%\end{figure}
%
%
