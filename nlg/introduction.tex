\section{Introduction}

Up to this point, we have  focused on content selection in a
\texttotext~generation system while relying on a trivial text generation
algorithm, copying or extracting text units verbatim from the input, to
perform the actual generation task.  In this chapter, we move to modeling the
actual language generation process after the content selection stages (i.e.
\hyperref[dlsal]{Chapters 3} and \hyperref[mlsal]{4}) have been performed.  We
focus in particular on the \sequencetosequence~model as a means of mapping a
representation of selected content to an appropriate natural language
utterance. \Sequencetosequence~models are a family of deep learning models
with bi-partite structure, possessing an encoder network which represents the
input and a decoder which generates output from encoder's state
\citep{sutskever2014}.  We tackle two issues, faithfulness and control, which
are necessary prerequisites for any practically useful
\sequencetosequence-based model of \naturallanguagegeneration.  These
concepts, which we define in more detail later in this chapter, can be
broadly construed as ensuring the decoder (i.e., the language model) in a
\sequencetosequence~model is constrained to generate utterances that respect
the semantics of the input (i.e. ensuring model faithfulness) 
while following a proscribed
discourse structure for the selected content (i.e. ensuring model control).

When data is
plentiful, the \sequencetosequence~paradigm has proven to be
incredibly adaptable to a variety of problem domains, and in the research
literature it 
has become the standard method for a 
host of language generation tasks \citep{xu2015,dusek2016,vaswani2017,fan2018}.
%In research, \sequencetosequence~architectures have become the standard 
%modeling method for a
  Recent evaluations of
end-to-end trained \sequencetosequence~models for dialogue generation have 
shown that they are capable of learning very natural text realizations of 
formal
\meaningrepresentation. In many cases, they  beat
rule and template based systems on human and automatic measures of quality
and naturalness 
\citep{dusek2020}.
 
\input{nlg/figures/examples.tex}

However, this powerful generation capability comes with a cost;
\deeplearning-based language models are notoriously difficult to control,
often producing quite fluent but  semantically misleading outputs. For
instance, \citet{dusek2020} note that in the E2E Generation Challenge
shared-task, \sequencetosequence~models were both some of the best and 
worst performers. One submission, a vanilla \sequencetosequence~model, scored first in human
evaluations of naturalness but last in quality (which they define as semantic
completeness and grammaticality).  In order for such models to truly be
useful, they must be capable of correctly generating utterances for novel
\meaningrepresentation s at test time.  In practice, even with
delexicalization \citep{dusek2016,juraska2018}, copy and coverage mechanisms
\citep{elder2018}, and over-generation plus reranking
\citep{dusek2016,juraska2018}, \deeplearning-based language generation models
still produce errors \citep{dusek2020}.


We study \sequencetosequence~model faithfulness on the \textit{task-oriented dialog generation} problem
\citep{mairesse2010,wen2015,dusek2018}, where a
\naturallanguagegeneration~model must map a \meaningrepresentation~(i.e., a
dialogue act with an associated set of attribute-value pairs\footnote{In the
literature and in industry, dialogue acts are sometimes called ``intents,''
and attribute-value pairs as ``slots'' and ``slot-fillers'' or ``entities.''})
to an appropriate natural language utterance (see \autoref{fig:nlgexamples}
for examples).  In the context of our broader work on \texttotext~generation,
we think of the \meaningrepresentation~input as an idealized representation of
the content selection stage in a \texttotext~generation model.  Studying
faithfulness and control in the closed-world domains of task-oriented dialog
generation allows us to make meaningful progress while minimizing unnecessary
complexity.

For instance, natural language summaries often contain information not
explicitly represented in the input. The source of this content is either from
common sense knowledge, generic or domain specific knowledge, or new facts
deduced from any combination of the input and prior knowledge
\citep{wiseman2017,wang2019}.  Evaluating the faithfulness of a neural language
generation model in this context is extremely difficult because it is not
clear if a generated utterance is due to the decoder language model or 
the encoder's representation of the input.

Instead, the task-oriented dialogue generation problems we study are developed
to be closed-world, narrow domain settings, where the totality of the
information needed to generate an utterance is represented by the
\meaningrepresentation. Additionally, the
semantics of the \meaningrepresentation~are explicit; there is no
information that needs to be realized by the language generation component
that requires additional inferences from the input.

We call a \naturallanguagegeneration~model that generates utterances 
that are semantically correct with respect to the input 
\meaningrepresentation, a \faithfulgeneration~model.
We posit that \sequencetosequence~models do not learn representations
of the input \meaningrepresentation~that correspond to basic features of the nature of utterance data, chiefly
that phrases denote fragments of \meaningrepresentation~which can be recombined with other fragments to systematically create new meanings/utterances. Instead, the learned representations are highly idiosyncratic, and often reflect spurious correlations and 
artifacts of the dataset that do not generalize well outside the training data.
This issue is symptomatic of 
neural models' lack of systematicity, which in turn  leads
to unfaithful language generation models
\citep{lake18}.
%fail to compositionally
%%reuse information in the training data, and that this is leads to failures
%in generating faithful utterances on novel test-set \meaningrepresentation s.


%to generalize to novel test-set
%\meaningrepresentation s and give some empirical evidence for this
%from the E2E Challenge dataset. 

\input{nlg/figures/examplenoise.tex}

To overcome these issues, we propose a novel data augmentation scheme,
called \textit{noise-injection sampling and self-training}, to
create synthetic \meaningrepresentation/utterance pairs which break spurious
correlations in the training dataset (see \autoref{fig:noiseyexample} for an
illustrative example). Our method makes use of a vanilla
\sequencetosequence~\naturallanguagegeneration~model, i.e. the kind described
by \citet{dusek2020} that produces natural but semantically incorrect
utterances (see \hyperref[fig:noiseyexample]{Figure 5.2b}), and a \meaningrepresentation~parser, both of which can
trained on the same parallel data.  We then use a noise-injection sampling
method \citep{cho2016} that allows us to generate semantically diverse yet
syntactically well formed utterance from the \naturallanguagegeneration~model
(see \hyperref[fig:noiseyexample]{Figure 5.2c}).
We obtain corrected \meaningrepresentation s for these sampled utterances using the
\meaningrepresentation~parser (see \hyperref[fig:noiseyexample]{Figure 5.2d}).  Using this procedure we can generate a
large collection of synthetic data points which do not exhibit the original spurious correlations. Training a new
\sequencetosequence~model on the union of the original training and novel
synthetic data yields a more \faithful~generation model with substantially
reduced semantic errors.



\input{nlg/figures/examplecontrol.tex}


%\sequencetosequence~models
%prevents 










 While a
\faithful~\sequencetosequence~model produces semantically correct output, in general
it is free to let the surface realization order of the \attributevalues~be 
determined by its language model. We show that we can actually control the realization
order by properly ``linearizing'' the \meaningrepresentation, that is, converting the \meaningrepresentation~into a linear sequence of discrete tokens, before
feeding it into the encoder. Our proposed \textit{alignment training}
linearization strategy for converting a \meaningrepresentation~to an 
encoder input sequence yields a highly controllable generation model, effectively moving implicit utterance planning from the decoder to the encoder.
We consider
\controllablegeneration~models to be a subset of \faithfulgeneration~models 
that can follow an externally provided discourse ordering plan.
See \autoref{fig:examplecontrol} for examples of such plans in the
context of  task-oriented dialogue generation.
 We find that alignment training endows both recurrent and transformer-based
\sequencetosequence~architectures with the controllable generation property as well 
as when fine tuning a large, pretrained \sequencetosequence~model.






%We believe that being able to specify
%this realization order ahead of time in the encoder 
%while having the decoder reliably
%follow the input plan, would be a highly benefitial capability for 
%a \sequencetosequence~language generation model. 
While most contemporary research practice prefers end-to-end solutions that
leave planning implicit, we argue that such fine grained control in a
\sequencetosequence~model  is highly desirable. 
Not only would it enable drawing deeper connections
between \sequencetosequence~models and 
the extensive literature on sentence or utterance level planning for language
generation \citep{reiter2000,walker2001,stone2003}, it would also allow 
for neural implementations of various psycho-linguistic
theories of discourse (e.g., Centering Theory \citep{grosz1995}, or
Accessibility Theory \citep{ariel2001}).  This could, in turn, encourage the
validation and/or refinement of additional psychologically plausible models of
language production. 

Ensuring robustness of the control behavior is also necessary to reliably incorporate 
neural language generation models
into larger language generation pipelines \citep{moryossef2019a,moryossef2019b,castroferreira2019}.
 However, as previously mentioned, neural models do not learn systematic 
representations
of the input, which can lead to errors in faithfulness or plan following
when generating from ordering plans not well represented in the training 
data. To mitigate this, 
we propose a phrase-based data augmentation scheme to collect 
additional examples that give explicit supervision of how constituent
phrases compose, and how that composition can systematically change the 
meaning (e.g. prepending ``not'' to a phrase systematically negates its
meaning). We show under extensive stress testing with randomly generated
plans that this data-augmentation improves the robustness of control.


%\meaningrepresentation~to a flat sequence of tokens, which we refer to as \linearizationstrategies,
%for use as input to the \sequencetosequence~encoder can affect
%the model's \faithfulness~at test time.
%What's more, we show  that \textit{alignment training}
%linearizing the \meaningrepresentation~in a way that aligns with the surface
%realization order of the corresponding reference utterance that during training  yields very 
%controllable models at test time. Such a model can now follow an arbitrary
%utterance plan at test time. Additionally, we propose a phrase-based data augmentation
%technique to improve the models ability to follow arbitrary or difficult plans. We find
%this controllable generation ability holds for a variety of popular architectures and a large, pretrained conditional language generation model.
%



%We further define a 
%\controllablegeneration~model as a \naturallanguagegeneration~model that can
%follow a externally provided discourse ordering plan
%(\controllablegeneration~models are a subset of \faithfulgeneration~models).
%See \autoref{fig:examplecontrol} for examples of utterance plans in the
%context of  task-oriented dialogue generation.
%
%While contemporary
%practice eschews modeling at this granularity, preferring
% models that  directly map an input \meaningrepresentation~to a 
%natural language utterance in an end-to-end differentiable fashion,
%we argue that robust and fine grained control in an \sequencetosequence~model
% is highly desirable. Not only would it enable drawing deeper connections
%between \sequencetosequence~models and 
%the extensive literature on sentence or utterance level planning for language
%generation \citep{reiter2000,walker2001,stone2003}, but it would also allow 
%for neural implementations of various psycho-linguistic
%theories of discourse (e.g., Centering Theory \cite{grosz1995}, or
%Accessibility Theory \cite{ariel2001}).  This could, in turn, encourage the
%validation and/or refinement of additional psychologically plausible models of
%language production.
 

%We train a controllable \sequencetosequence~model, we propose \textit{alignment training}, where we represent the \meaningrepresentation~input as a  
%sequence of tokens  align the \attributevalue s of 

%In what follows, we introduce the \meaningrepresentation s used 
%for task-oriented dialogue generation (\autoref{sec:mr4tod}). Then we give
%some background on how neural \naturallanguagegeneration~are used to generate
%utterances from the provided \meaningrepresentation~(\autoref{mrtproblemdef}).
%
%

In what follows, we introduce the \meaningrepresentation s used 
for task-oriented
dialogue generation in more detail (\autoref{sec:mr4tod}) and provide
some background on \sequencetosequence~modeling for 
\meaningrepresentation-to-text generation (\autoref{mrtproblemdef}). We then turn
to our main contributions,
our noise-injection sampling and self-training data-augmentation method 
for \faithfulgeneration~(\autoref{sec:nlgfg}),
and alignment training linearization~for \controllablegeneration~(\autoref{sec:nlgcg}), before concluding.

%~\\~\\
%
%\linearizationstrategies,
%that is, mappings from \meaningrepresentation~to 
%\naturallanguagegeneration~model input sequences, can effect the 
%\faithfulness~of the model. In particular, we show that during training that
%linearizing the \meaningrepresentation~in a way that aligns with the surface
%realization order of the corresponding reference utterance yields very 
%controllable models at test time. Such a model can now follow an arbitrary
%order at test time. Additionally, we propose a phrase-based data augmentation
%technique to improve the models ability to follow arbitrary orders. We find
%this controllable generation ability holds for a variety of popular architectures and a large, pretrained conditional language generation model.
%
%
%
%
%~\\~\\
%
%
%
% Instead this knowledge is either common sense
%knowledge, domain specific knowledge, or knowl
%
%derived from background
%knowledge of the world that is not represented in the input, and it 
%becomes difficult to evaluate the faithfulness in this context
%
%~\\~\\
%
%
%by making the 
%knowledge base explicit (the model can only use facts represented in the
%input \meaningrepresentation) and keeping the semantics simple and easy
%to check by a non-domain expert (the mapping from \meaningrepresentation to phrases in the utterance is roughly one-to-one, and does not require making a deductive leap).
%
%
%
%Even in narrow domains like generating sports summaries,
%making distinctions between knowledge represented in the input and what
%is simply part of the language model can be difficult \cite{wiseman2017,wang2019}.
%~\\~\\
%
%
%Faithfulness
%and control are incredibly difficult to study in open-domain settings
%like news. 
%in open-domain summarization
%where making distinctions between 
%
%
%  treating the  
%\meaningrepresentation s as an idealized representation of the content 
%selection stage in a \texttotext~generation model. 
%
%
%, i.e. dialogue acts with an associated set of
%attribute-value pairs 
%
%
%
%
%
%%model 
%In this problem setting, we work from
%an idealized representation
%of content 
%
%(as if we were receiving output from a a hypothetical content selection model from the previous chapter) , we now focus on the text generation process in more detail. 
%
%
%%In particular, we focus on ensuring the language generation component is more
%%than just a good language model producing fluent text but also produces 
%%semantically correct or consistent output given its conditioning inputs.
%%We 
%
%
% 
%%\input{example.tex}
%
%
%We call a \naturallanguagegeneration~model that generates utterances 
%that are semantically correct with respect to the input 
%\meaningrepresentation~a \faithfulgeneration~model. While a
%\faithfulgeneration~model produces semantically correct output, in general
%it is free to let the surface realization order of output utterances
%be determined by its language model. We further define a 
%\controllablegeneration~model as a \naturallanguagegeneration~model that can
%follow a externally provided discourse ordering plan. 
%\Controllablegeneration~models are a subset of \faithfulgeneration~models.
%
%
%
%In this chapter we develop training strategies to produce both \faithful~and
%\controllablegeneration~models. In \autoref{sec:fg}, we propose a 
%data augmentation strategy for using an 
%un\faithful~\naturallanguagegeneration~model and 
%a \naturallanguageunderstanding~model to 
%generate novel \meaningrepresentation/utterance pairs that are not well
%represented in the original training data. Crucially, we use a noise-injection
%sampling method that allows us to generate semantically diverse 
%yet syntactically well formed outputs. Using this procedure we can generate
%a large collection of synthetic data points. Training a new 
%\sequencetosequence~model on the union of the original training and novel
%synthetic data yields a more \faithfulgeneration~model, with substantially
%reduced semantic errors relative to very competitive baselines. 
%
%
%
%In the next sections, we present related works, before formally defining the 
%\meaningrepresentation~to~text generation task and models, before developing
%the data augmentation techniques for \faithfulgeneration~\autoref{somesec} 
%and \linearizationstrategies~for~\controllablegeneration~\autoref{somesec}.
%
%
% 
%
%
