\subsection{An Idealized Data-Augmentation Protocol}
\label{sec:ideal}

We now introduce an idealized data-augmentation protocol and discuss some
potential pitfalls and bottlenecks before proposing our implementation 
of it.
Let $\corpus_\mrspace$ and $\corpus_\outSpace$
be the empirical distributions (i.e. training dataset distributions) over the \meaningrepresentations~and utterances
respectively. The emipirical distributions exhibit various dataset creation/annottation
artifacts. For example, we have that some attributes  are correlated
with length (i.e., $\corpus_\mrspace(a \in \mr, \setsize{\mr} = k) \ne 
\corpus_\mrspace(a \in \mr)\corpus_\mrspace(\setsize{\mr} = k)$) or 
certain attributes with each other
(i.e., $\corpus_\mrspace(a_1, a_2 \in \mr) \ne 
\corpus_\mrspace(a_1 \in \mr)\corpus_\mrspace(a_2\in \mr)$).



Ideally, we could construct novel \meaningrepresentation~examples such that
their distributions did not display these correlations. Let us assume we
have such a distrubtion, $\daMrDist$, from which we can sample novel
utterances. Given a sample $\samplmr \sim \daMrDist$, we would then need
a conditional distribution $\daUttDist(\samplmr)$ from which to 
draw the appropriate companion utterance $\samutttoks$ such that $\denotes{\samutttoks} = \samplmr$ while the naturalness/grammaticality of $\samutttoks$
was consistent with the empirical distribution, i.e. $\daUttDist \approx \corpus_\outSpace$. Having these two distributions, we could follow the
simple data-augmentation protocol in \autoref{alg:idealda} to obtain
a more systematic language generation model $\gen_*$.



Coming up with a 
\meaningrepresentation~distribution, $\daMrDist$, is fairly straightforward.
For example we could just sample the size of the \meaningrepresentation, $k$,
uniformly at random, then sample the $k$ \attributes~uniformly at random 
without replacement. This would ensure that attributes and \meaningrepresentation~size are independent and ensure that \attributes~are not correlated with
each other. To make up for the fact that some \attributevalues~are over-represented in the training set, we could sample values inversely proportional
to their empirical frequency. This results in the following data generation
process for 
\begin{singlespace}\[
\tilde{\mr}  = \left[\!\!\left[ 
\begin{array}{c} 
\delta~~~~~~~ \\
\AV{$a_1$}{$v_1$} \\ \vdots \\ \AV{$a_k$}{$v_k$}  
\end{array}  
\right]\!\!\right] \sim \daMrDist,\]\end{singlespace}
% Then for each of the attributes, values could be
%sampled inversely proportional to their occurrence in the training data, i.e.
{
\begin{minipage}{0.9\textwidth}
\begin{singlespace}
\noindent \textit{(1) Draw a dialogue act.}
\[
  \delta \sim \operatorname{Uniform}(\left\{\delta_1, \delta_2,\ldots\right\}) 
\]
\noindent \textit{(2) Draw a \meaningrepresentation~size $k$.}
\[
  k \sim \operatorname{Uniform}(\{k_{min}, \ldots, k_{max}\}) 
\]
\noindent \textit{(3) Sample $k$ attributes without replacement.}
\[
a_i  \sim \operatorname{Uniform}(\{name, \ldots, near, eat\_type\}\setminus\{a_1,\ldots,a_{i-1}\}) \quad \forall i: i \in  \{1,\ldots, k\}\]
\noindent \textit{(4) Sample a value $v_i$ for each attribute $a_i$.}
\[ v_i  \sim \operatorname{Categorical}\left(\operatorname{count}(v_1)^{-1}, \operatorname{count}(v_2)^{-1},\ldots\right)  \quad \forall i: i \in \{1,\ldots,k\}. \]
\end{singlespace}
\end{minipage}}
%\begin{align*}
%\operatorname{count}(a, v) & = \sum_{(\mr, \utttoks) \in \corpus} \mathds{1}\{\AV{$a$}{$v$} \in \mr  \}\\
%p(v|a) & = \frac{\operatorname{count}(a,v)^{-1}}{\sum_{v^\prime \in {\mrvocab}_a}  \operatorname{count}(a,v^\prime)^{-1}} \\
%a_i & \sim \operatorname{Uniform}(\{name, \ldots, near, eat\_type\}\setminus\{a_1,\ldots,a_{i-1}\}) & \forall i: i \in  \{1,\ldots, k\}\\
%v_i & \sim p(\cdot|a) & \forall i: i \in \{1,\ldots,k\} \\
%\tilde{\mr} & = \left[\!\!\left[ 
%\begin{array}{c} 
%\textsc{Inform} \\
%\AV{$a_1$}{$v_1$} \\ \vdots \\ \AV{$a_k$}{$v_k$}  
%\end{array}  
%\right]\!\!\right]
%\end{align*}\end{singlespace}
%This procedure should produce valid \meaningrepresentations, and by 
%definition $\daMrDist \ne \corpus_\mr$. Additionally, the co-occurance
%of an \attribute~and a particular \meaningrepresentation~size will now be 
%independent, and the co-occurrance of pairs of attributes will also be independent. 
%





\begin{algorithm}[t]
$\augdata \gets \{\}$\\
\While{$\setsize{\augdata} < \numSamples$}{
$\tilde{\mr} \sim \daMrDist$ \\
$\boldsymbol{\tilde{\utttoks}} \sim \daUttDist(\boldsymbol{\tilde{\mr}})$\\
%\If{ $\lnot \filter(\tilde{\mr}, \boldsymbol{\tilde{\utttoks}})$}{ $\augdata \gets \augdata \cup \{(\tilde{\mr}, \boldsymbol{\tilde{\utttoks}}) \}$ }
$\augdata \gets \augdata \cup \{(\tilde{\mr}, \boldsymbol{\tilde{\utttoks}}) \}$
}
%    \KwResult{Salience judgements $\bsals = \left[ \bsal_1, \ldots, \bsal_\docSize\right]$}
$\gen_* \gets \operatorname{Train}(\corpus \cup \augdata)$\\
\KwResult{$\gen_*$}
    \caption{Idealized Data-Augmentation and Training}
\label{alg:idealda}
\end{algorithm}

%If the novel \meaningrepresentations~are drawn from a distribution, 
%$\daMrDist$, such that $\daMrDist \ne \corpus_\mr$, 
%and the novel utterances are generated from $\daUttDist(\tilde{\mr})$
% such that $\denotes{\boldsymbol{\tilde{\utttoks}}} = \tilde{\mr}$
%while maintaining their fluency/naturalness (i.e., $\daUttDist \approx \corpus_\utttoks$),
%then 
%it is possible that that when training a \sequencetosequence~on the union 
%of original training data and synthetic data, the resulting model, $\gen_*$,
% will behave
%more systematically, which means more faithfully in our context.

Unfortunately, it is not clear how we implement utterance distribution
$\daUttDist(\samplmr)$ since if we had an utterance generation method that could
respond systematically to non-training data distributed \meaningrepresentations, we wouldn't need to perform data augmentation in the first place. As a starting point, 
we consider ways of generating samples from a base model $\gen_0$ which 
trained on the available training data, i.e. $\gen_0 = \operatorname{Train}(\corpus)$.


