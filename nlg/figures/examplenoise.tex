\newtcbox{\greenbox}[1][]{colframe=green, colback=green!15, boxrule=0.1mm,
                       nobeforeafter, tcbox raise base, shrink tight, extrude
                       by=0.32mm, #1}

\newtcbox{\redbox}[1][]{colframe=red, colback=red!15, boxrule=0.1mm,
                       nobeforeafter, tcbox raise base, shrink tight, extrude
                       by=0.32mm, #1}


\usetikzlibrary{calc}
\begin{figure}[p]

  \centering 
  {
  \begin{tikzpicture}
    
    %%% Block A %%%

    \node[text width=0.9\textwidth,align=left] (a) at (0,0) 
    {(a) An example \meaningrepresentation/utterance pair, $(\mr, \utttoks)$,
        exhibiting a 
        spurious correlation from the training set: 
         \greenbox{high priced} restaurants tend to be \redbox{highly rated.}};
    \node[anchor=west] (a1) at ($(a.west)+(0,2)$) {
        $\left[\!\!\left[\begin{array}{l} \textsc{Inform} \\ 
            \AV{name}{Aromi} \\ 
            \textrm{customer\_rating=}\redbox{\textrm{5 out of 5}} \\ 
            \textrm{price\_range=}\greenbox{\textrm{high}} 
            \end{array} \right]\!\!\right]$};

    \node[draw,dotted,text width=4cm,anchor=east] (a2) at ($(a.east)+(0,2)$) 
        {\textit{The Aromi is in the \greenbox{high price range}, but it's 
         worth it as it has a \redbox{5 star rating.}}};

    %%% Block B %%%

    \node[text width=0.9\textwidth,align=left] (b) at (0,-4) 
        {(b) An NLG model trained on this data may struggle to generalize correctly at test time.  Here, the model failed to realize the \redbox{customer rating} correctly.};

    \node[anchor=west] (b1) at ($(b.west)+(0,2)$) {
        $\left[\!\!\left[\begin{array}{l} \textsc{Inform} \\
            \AV{name}{Loch Fyne} \\
            \textrm{customer\_rating=}\redbox{\textrm{1 out of 5}} \\
            \textrm{price\_range=}\greenbox{\textrm{high}} 
            \end{array} \right]\!\!\right]$};

    \node[draw,dotted,text width=4cm,anchor=east] (b2) at ($(b.east)+(0,2)$) 
        {\textit{The Loch Fyne has a \greenbox{high price range} and a 
    \redbox{5 star rating.}}}; 
    \node at (3,-2.5) {\includegraphics[scale=0.50]{images/emoji.pdf}  };

    \node[draw] (b3) at ($(b1.east)!0.5!(b2.west) $) {NLG Model};

    \draw[line width=0.5mm,->] (b1.east) -- (b3.west);
    \draw[line width=0.5mm,->] (b3.east) -- (b2.west);
        
    %%% Block C %%%
    
    \node[text width=0.9\textwidth,align=left] (c) at (0,-8) 
        {(c) Noise-injection sampling can produce semantically divergent 
         outputs that break correlations but are not faithful to the input 
         \meaningrepresentation.};

    \node[anchor=west] (c1) at ($(c.west)+(0,2)$) {
        $\left[\!\!\left[\begin{array}{l} \textsc{Inform} \\ 
            \AV{name}{Loch Fyne} \\ 
            \textrm{customer\_rating=}\redbox{\textrm{1 out of 5}} \\ 
            \textrm{price\_range=}\greenbox{\textrm{high}} 
            \end{array} \right]\!\!\right]$};

    \node[draw,dotted,text width=4cm,anchor=east] (c2) at ($(c.east)+(0,2)$) 
        {\textit{The Eagle has a \redbox{1 star rating} and 
        \greenbox{high prices.} It serves Japanese cuisine.}};

    \node[draw,align=center] (c3) at ($(c1.east)!0.5!(c2.west)$) 
        {NLG Model \\+ Noise-Injection};
    
    \draw[line width=0.5mm,->] (c1.east) -- (c3.west);
    \draw[line width=0.5mm,->] (c3.east) -- (c2.west);
 
    %%% Block D %%%
    
    \node[text width=0.9\textwidth,align=left] (d) at (0,-12) 
        {(d) The correct \meaningrepresentation~can be recovered
         with a parser model. Adding $(\pdaPredMr,\predutttoks)$ to the 
         dataset can help break the 
         correlation between price and rating.};

           
    \node[anchor=west] (d1) at ($(d.west)+(0,2)$) {
        $\left[\!\!\left[\begin{array}{l} \textsc{Inform} \\ 
            \AV{name}{The Eagle} \\ 
            \textrm{customer\_rating=}\redbox{\textrm{1 out of 5}} \\ 
            \textrm{price\_range=}\greenbox{\textrm{high}}\\ 
            \AV{food}{Japanese} \end{array} \right]\!\!\right]$};
    
    \node[anchor=north east] at ($(d1.north east)-(0.25,0.05)$) {$(\pdaPredMr)$};
    \node[anchor=north east] at ($(a1.north east)-(0.25,0.05)$) {$(\mr)$};
    
    \node[anchor=north east] at ($(c2.north east)+(0.10,0)$) 
        {$(\predutttoks)$};
    \node[anchor=north east] at ($(a2.north east)+(0.10,0)$) 
        {$(\utttoks)$};

    \node[draw,align=center] (d3) at ($(c3)-(0,4)$) {MR Parser};

    \node (z1) at ($(c2.east)+(0.2,0)$) {};
    \node (z2) at ($(c2.east)+(0.2,-4)$) {};

    \draw[line width=0.5mm,->] (c2.east) -- (z1.center) -- (z2.center) -- (d3.east);
    \draw[line width=0.5mm,->] (d3.west) -- (d1.east);

    \node (h1) at ($(c1.west)+(-0.2,0)$) {};
    \draw[line width=0.5mm,white,-] (c1.west) -- (h1.center);
%
%
%

\end{tikzpicture}}
\caption{An example of how noise-injection sampling can produce novel training examples that remove spurious correlations in the training data.}
\label{fig:noiseyexample}
\end{figure}
